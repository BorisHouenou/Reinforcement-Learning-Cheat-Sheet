\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{Agent-Environment Interface}{1}{section*.1}}
\@writefile{toc}{\contentsline {section}{Policy}{1}{section*.2}}
\newlabel{eq: policy}{{1}{1}{Policy}{equation.0.1}{}}
\@writefile{toc}{\contentsline {section}{Reward}{1}{section*.3}}
\newlabel{eq: total_reward}{{2}{1}{Reward}{equation.0.2}{}}
\@writefile{toc}{\contentsline {subsection}{Markov Decision Process}{1}{section*.4}}
\@writefile{toc}{\contentsline {section}{Value Function}{1}{section*.5}}
\newlabel{eq: value_func}{{4}{1}{Value Function}{equation.0.4}{}}
\@writefile{toc}{\contentsline {subsection}{Optimal}{1}{section*.6}}
\newlabel{eq: value_optimal}{{5}{1}{Optimal}{equation.0.5}{}}
\@writefile{toc}{\contentsline {section}{Action-Value (Q) Function}{1}{section*.7}}
\newlabel{eq: q_func}{{6}{1}{Action-Value (Q) Function}{equation.0.6}{}}
\@writefile{toc}{\contentsline {subsection}{Optimal}{1}{section*.8}}
\newlabel{eq: action_value_optimal}{{7}{1}{Optimal}{equation.0.7}{}}
\@writefile{toc}{\contentsline {section}{Bellman Equation}{1}{section*.9}}
\@writefile{toc}{\contentsline {subsection}{Value Function}{1}{section*.10}}
\newlabel{eq: value_bellman}{{9}{1}{Value Function}{equation.0.9}{}}
\newlabel{eq: action_value_bellman}{{10}{1}{Value Function}{equation.0.10}{}}
\@writefile{toc}{\contentsline {section}{Dynamic Programming}{1}{section*.11}}
\@writefile{toc}{\contentsline {subsection}{Policy Iteration}{1}{section*.12}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Policy Iteration}}{1}{algocf.1}}
\@writefile{toc}{\contentsline {subsection}{Value Iteration}{1}{section*.13}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Value Iteration}}{1}{algocf.2}}
\@writefile{toc}{\contentsline {section}{Monte Carlo Methods}{1}{section*.14}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Monte Carlo first-visit }}{2}{algocf.3}}
\@writefile{toc}{\contentsline {section}{Sarsa}{2}{section*.15}}
\@writefile{toc}{\contentsline {subsection}{$n$-step Sarsa}{2}{section*.16}}
\@writefile{toc}{\contentsline {subsection}{Forward View Sarsa($\lambda $)}{2}{section*.17}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Sarsa($\lambda $)}}{2}{algocf.4}}
\@writefile{toc}{\contentsline {section}{Temporal Difference - Q Learning}{2}{section*.18}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Q Learning}}{2}{algocf.5}}
\@writefile{toc}{\contentsline {section}{Deep Q Learning}{2}{section*.19}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces Deep Q Learning}}{2}{algocf.6}}
\@writefile{toc}{\contentsline {section}{Double Deep Q Learning}{2}{section*.20}}
